0	55	Coordination is a common syntactic phenomena, appearing in 38.8% of the sentences in the Penn Treebank (PTB) (Marcus et al., 1993), and in 60.71% of the sentences in the Genia Treebank (Ohta et al., 2002).
3	62	For example, in: “He has the government’s blessing to [build churches] and [spread Unificationism] in that country.” the conjuncts are incorrectly predicted by both parsers: Berkeley: “He has the government’s blessing to [build churches] and [spread Unificationism in that country].” Zpar: “He [has the government’s blessing to build churches] and [spread Unificationism in that country].” In this work we focus on coordination boundary prediction, and suggest a specialized model for this task.
4	23	We treat it as a ranking task, and learn a scoring function over conjuncts candidates such that the correct candidate pair is scored above all other candidates.
13	23	For example, in: “The Jon Bon Jovi Soul Foundation [was founded in 2006] and1 [exists to combat issues that force (families) and2 (individuals) into economic despair].” The coordinator and1 links the conjuncts surrounded with square brackets and the coordinator and2 links the conjuncts surrounded with round brackets.
46	44	The coordination classification and candidate extraction components are described in Section 5.
48	28	As noted in Section 2.1, many conjuncts spans have similar syntactic structure.
53	19	This architecture is similar to Siamese Networks, which are used for learning similarity functions in vision tasks (Chopra et al., 2005).
58	21	Given two spans of lengths k and m with corresponding vector sequences u1:k and v1:m we encode each sequences using an LSTM, and take the euclidean distance between the resulting representations: Sym(u1:k, v1:m) = ||LSTM(u1:k)− LSTM(v1:m)|| The network is trained such that the distance is minimized for compatible spans and large for incompatible ones in order to learn that vectors that represent correct conjuncts are closer than vectors that do not represent conjuncts.
63	16	A way to allow the model access to higher levels of syntactic symmetry is to represent each word as the projection of the grammatical functions from the word to the root.2 For example, the projections for the first conjunct in Figure 2 are: VP VB cut VP NP PRP$ their VP NP NNS risks This decomposition captures the syntactic context of each word, but does not uniquely determine the structure of the tree.
74	78	The replacement component is based on the observation that, in many cases, the coordination phrase can be replaced with either one of its conjuncts while still preserving a grammatical and semantically coherent sentence (Section 2.2) When attempting such a replacement on incorrect conjuncts, the resulting sentence is likely to be either syntactically or semantically incorrect.
75	19	For example, in the following erroneous analysis: “Rudolph Agnew, [55 years old] and [former chairman] of Consolidated Gold Fields PLC” replacing the conjunction with the first conjunct results in the semantically incoherent sequence “Rudolph Agnew, 55 years old of Consolidated Golden Fields, PLC”.4 Our goal is to distinguish replacements resulting from correct conjuncts from those resulting from erroneous ones.
81	25	Likewise, replacing the coordination phrase with Conj1 results in connection point between Conj1 and Post.
85	25	In addition to the symmetry and replacement signals, we also incorporate some scores that are derived from the Berkeley parser.
88	14	Each candidate {(i, j), (l,m)} is assigned two numerical features based on this ranking: its position in the ranking, and the ratio between its score and the score of the adjacent higher-ranked candidate.
91	32	Finally, the score of a candidate {(i, j), (l,m)} in a sentence with words w1:n and POS tags p1:n is computed as: SCORE(w1:n, p1:n, {(i, j), (l,m)}) = MLP ( Sym(vPathi:j , v Path l:m ) ◦Repl(w1:n, i, j, l,m) ◦Repl(p1:n, i, j, l,m) ◦ Feats(i, j, l,m) ) where vPathi:j and v Path l:m are the vectors resulting from the path LSTMs, and Sym, Repl and Feats are the networks defined in Sections 4.1 – 4.3 above.
92	16	The network is trained jointly, attempting to minimize a pairwise ranking loss function, where the loss for each training case is given by: loss = max(0, 1− (ŷ − yg)) where ŷ is the highest scoring candidate and yg is the correct candidate.
93	42	The model is trained on all the coordination cases in Section 2–21 in the PTB.
102	27	When evaluating on NP coordination, we depart from the unrealistic scenario used in most previous work where the type of coordination is assumed to be known a-priori, and train a specialized model for predicting the coordination type.
105	20	Evaluating on gold coordinations results in F1 scores of 95.06 (dev) and 93.89 (test).
107	15	When evaluating on the PTB, we compare to the conjunction boundary predictions of the generative Berkeley parser (Petrov et al., 2006) and the discriminative Zpar parser (Zhang and Clark, 2011).
126	16	Thus, in our symmetry component we opted to not rely on predicted tree structures, and instead use the simpler option of representing each conjunct by its sequence of POS tags.
127	79	To handle coordination phrases with more than two conjuncts, we extract candidates which includes up to 7 spans and integrate the first and the last span in the model features.
128	148	Like Hara et al., we use gold POS.
130	25	Our proposed model achieves Recall score of 64.14 (2.64 Recall points gain over Hara et al.) and significantly improves the score of several coordination types.
139	35	The words and POS embeddings are shared between the symmetry and replacment components.
143	17	Our model combines four signals: symmetry, wordlevel replacement, POS-level replacement and features from Berkeley parser.
144	66	Table 4 shows the PTB dev-set performance of each sub-model in isolation.
147	64	Figure 4 lists correct and incorrect predictions by each of the components, indicating that the individual models are indeed capturing the patterns they were designed to capture – though these patterns do not always lead to correct predictions.
160	37	Our model is based on the observation that (a) conjuncts tend to be similar and (b) that replacing the coordination phrase with a conjunct results in a coherent sentence.
161	68	Our models rely on syntactic information and do not incorporate resources external to the training treebanks, yet improve over state-of-the-art parsers on the coordination boundary prediction task.
