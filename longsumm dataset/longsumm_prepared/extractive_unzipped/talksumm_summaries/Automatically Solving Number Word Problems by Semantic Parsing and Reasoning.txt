1	65	However, it is still a big challenge nowadays to design algorithms to automatically solve even primary-school-level math word problems (i.e., math problems described in natural language).
4	22	In symbolic approaches (Bobrow, 1964a, b; Charniak, 1968; Bakman, 2007; Liguda & Pfeiffer, 2012), math problem sentences are transformed to certain structures by pattern matching or verb categorization.
15	29	Our approach falls into the symbolic category, but makes improvements over previous symbolic methods in the following ways, ______________________________________ * Work done while this author was an intern at Microsoft Research 1132 1) We introduce a systematic way of parsing NL text, based on context-free grammar (CFG).
17	46	We split the problem set into a development set (called dev set) and a test set.
19	36	Three metrics (precision, recall, and F1) are employed to measure system performance from multiple perspectives, in contrast to all previous work (including the statistical ones) which only measures accuracy.
21	50	We hope to extend our techniques to handle general math word problems in the future.
53	18	2) A semantic parser which transforms natural language sentences of a math problem into DOL representation.
55	28	Every meaningful piece of NL text is represented in DOL as a semantic tree of various node types.
57	22	It contains two semantic trees, corresponding to the two sentences.
74	26	DOL supports three kinds of functions: noun functions, verb functions, and modifier functions.
80	40	The function is specified below, nf.list $1: class; $2: math.number return type: t.list<$1> return value: An entity list with cardinality $2 and element type $1 For example nf.list(math.number,5) returns a list containing 5 elements of type math.number.
92	28	In Figure 2, the same variable v1 (meaning a variable with ID 1) is assigned to two sub-trees in the first sentence and one sub-tree in the second sentence.
94	27	DOL has some nice characteristics that are critical to building a high-precision math problem solving system.
98	16	A valid DOL tree must satisfy the type-compatibility property: Type-compatibility: The type of each child of a function node should match the corresponding argument type of the function.
101	21	sum of 100 [unreasonable text] nf.math.sum!2(100) [invalid DOL tree] sum of 3 and Jordan [unreasonable text] nf.math.sum!2({3, â€œJordanâ€}) [invalid tree] Second, we maintain in DOL an open-domain type system.
114	19	Third, DOL has template classes and built-in data structures like t.list and nf.list to facilitate the representation of math concepts.
123	116	Letâ€™s use the following problem (i.e., the first problem of Figure 1) to illustrate, One number is 16 more than another.
125	37	For this problem, it is difficult to determine whether â€œthe smaller numberâ€ refers to â€œone numberâ€ or â€œanotherâ€ in directly constructing logical forms.
128	20	To enable this mechanism, the meaning representation language should support a lazy variable ID assignment and keep as much information (e.g., determiners, plurals, modifiers) from the noun phrases as possible.
129	60	DOL is a language that always keeps the structure information of phrases, whether or not it has been assigned a variable ID.
130	54	In summary, compared with other languages, DOL has some unique features which make it more suitable for our math problem solving scenario.
131	22	Our parsing algorithm is based on context-free grammar (CFG) (Chomsky, 1956; Backus, 1959; Jurafsky & Martin, 2000), a commonly used mathematical system for modeling constituent structure in natural languages.
134	18	Table 2 shows some example CFG rules in our system for mapping DOL nodes to natural language word sequences.
140	21	About 35 classes and 200 functions are obtained in this way.
142	86	Classes: Additional classes and grammar rules are obtained from two data sources: Freebase 3 types, and automatically extracted lexical semantic data.
143	47	By treating Freebase types as DOL classes and the mapping from types to lexical names as grammar rules, we get the first version of grammar for classes.
144	26	To improve coverage, we run a term peer similarity and hypernym extraction algorithm (Hearst, 1992; Shi et al., 2010; Zhang et al., 2011) on a web snapshot of 3 billion pages, and get a peer-similarity graph and a collection of is-a pairs.
148	31	Given the cleaned isa data, we sort the type names by weight and manually create classes for top-1000 type names.
168	33	The score of a tree T is the weighted average of the scores of its sub-trees, ğ‘º(ğ‘») = âˆ‘ ğ‘³(ğ‘»ğ’Š) âˆ™ ğ‘º(ğ‘»ğ’Š) ğ’Œ ğ’Š=ğŸ âˆ‘ ğ‘³(ğ‘»ğ’Š) ğ’Œ ğ’Š=ğŸ âˆ™ ğ’‘(ğ‘») (3) where ğ‘‡ğ‘– is a sub-tree, and ğ¿(ğ‘‡ğ‘–) is the number of words to which the sub-tree corresponds in the original text.
173	42	Among all candidate DOL trees yielded during parsing, we return the one with the highest score as the final parsing result.
