0	47	Many controversial topics in real life divide us into opposing camps, such as whether to ban guns, who should become president, or what phone to buy.
3	62	Take the following argument in favor of the right to bear arms from the web portal idebate.org: Argument “Gun ownership is an integral aspect of the right to self defence.
5	20	[...]” (premise) While the conclusion seems well-reasoned, the web portal directly provides a counter to the argument: Counterargument “Burglary should not be punished by vigilante killings of the offender.
7	29	Perversely, the danger of attack by homeowners may make it more likely that criminals will carry their own weapons.
9	31	[...]” As in this example, we observe that a counterargument often takes on the aspects of the topic invoked by the argument, while adding a new perspective to its conclusion and/or premises, conveying the opposite stance.
10	63	Research has tackled the stance of argument units (Bar-Haim et al., 2017) as well as the attack relations between arguments (Cabrio and Villata, 2012).
15	29	In the general case, we cannot expect prior knowledge of an argument’s topic.
16	20	Following the observation above, we thus just hypothesize the best counterargument to invoke the same aspects as the argument while having the opposite stance.
79	21	On the portal idebate.org, diverse controversial topics of usually rather general interest are discussed in debates, subsumed under 15 themes, such as “economy” and “health”.
105	18	All tasks consider all true argumentcounterargument pairs, while differing in terms of what arguments (points and/or counters) from which context (same debate, same theme, or entire portal) are candidates for a given argument.
130	19	While the differences were not large, stems worked best and stem 1-grams sufficed.
138	29	Embedding Argument Similarity We evaluated five pretrained word embedding models for representing arguments in first tests: GoogleNewsvectors (Mikolov et al., 2013), ConceptNet Numberbatch (Speer et al., 2017), wiki-news-300d-1M, wiki-news-300d-1M-subword, and crawl-300d-2M (Mikolov et al., 2017).
158	23	Word and Embedding Unit Similarities In particular, we follow the notion that a counterargument attacks either the conclusion of an argument, the argument’s premises, or both.
159	19	As a consequence, we compute two word and two embedding similarities as specified above for each candidate counterargument; once to the argument’s conclusion (called wc and ec for words and embeddings respectively) and once to the argument’s premises (wp and ep).
169	47	We seek to thereby find the most dissimilar candidate among the similar candidates.
172	37	We hence evaluate different combinations empirically below.
190	21	On one hand, we check the need for distinguishing conclusions and premises by comparing to the word argument similarity (w) and the embedding argument similarity (e).
196	44	Ctr.’s Counters Opposing Arguments Counters Arguments Counters Arguments # Baseline / Approach @1 R @1 R @1 R @1 R @1 R @1 R @1 R @1 R w Word argument similarity 65.9 2 48.5 2 42.5 3 30.0 4 44.1 5 28.3 10 39.7 22 21.8 49 e Embedding argument similarity 62.9 2 44.6 2 51.6 2 36.8 4 38.8 7 32.9 10 34.2 39 23.9 55 w↓ Word unit similarity minimum 53.8 2 38.4 3 45.9 3 33.7 5 28.5 22 24.8 42 21.4 206 18.5 403 w↑ Word unit similarity maximum 66.1 2 48.0 2 44.0 3 30.2 4 44.0 5 28.3 9 38.0 21 21.2 44 w× Word unit similarity product 64.9 2 49.5 3 56.1 2 40.7 4 44.3 18 36.8 35 37.8 177 26.8 354 w+ Word unit similarity sum 71.5 1 53.7 2 54.1 2 39.1 4 49.0 4 36.8 7 44.7 17 28.6 33 e↓ Embedding unit sim.
212	149	From the eight unit similarity baselines, w+ performs best on five tasks (e× twice, w× once).
214	19	In that task, however, the mean ranks of w+ (33) and particularly of w× (354) are much worse than for e× (21), meaning that words are insufficient to robustly find counterarguments.
220	28	Entire Portal: Arguments Accuracy@1 Mean Rank Although our scoring model thus does not solve the retrieval tasks, we conclude that it serves as a robust approach to rank the best counterargument high.
233	24	We did not aim to engineer the best approach to this retrieval task, but to study whether we can model the simultaneous similarity and dissimilarity of a counterargument to an argument computationally.
234	39	For the restricted domain of debate portal arguments, our main result is quite intriguing: The best model (we↑) rewards a high overall similarity to the argument’s conclusion and premises while punishing a too high similarity to either of them.
236	59	This speaks for our hypothesis that the best counterargument often just addresses the same topical aspects with opposite stance.
238	43	Apart from some hyperparameters, however, our model is unsupervised and it does not make any assumption about an argument’s topic.
242	18	To obtain further insights into the nature of counterarguments, deeper linguistic analysis along with supervised learning may be needed, though.
244	42	The intended practical application of our model is to retrieve counterarguments in automatic debating technologies (Rinott et al., 2015) and argument search (Wachsmuth et al., 2017b).
245	160	While debate portal arguments are often suitable in this regard, in general not always a real counterargument exists to an argument.
246	94	Still, returning one that addresses similar aspects with opposite stance makes sense then.
247	110	An alternative would be to generate counterarguments, but we believe that humans are better than machines in writing them — currently.
