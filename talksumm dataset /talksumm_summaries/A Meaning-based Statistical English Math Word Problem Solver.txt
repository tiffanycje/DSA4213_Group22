0	21	The math word problem (MWP) (see Figure 1) is frequently chosen to study natural language understanding and simulate human problem solving (Bakman, 2007; Hosseini et al., 2014; Liang et al., 2016) for the following reasons: (1) the answer to the MWP cannot be simply extracted by performing keyword/pattern matching.
6	14	According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches (Mukherjee and Garain, 20081; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers.
7	26	This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra and Baral, 2016; Roy and Roth, 2017), which also checks the entity-attribute consistency while solving the problem.
8	17	1 It is a survey paper which reviews most of the rule-based approaches before 2008.
11	15	In contrast, the performance of purely statistics-based approaches deteriorates significantly when the MWP includes either irrelevant information or information gaps (Hosseini et al., 2014), as it is solved without first understanding the meaning.
22	22	In this paper, we adopt the framework proposed by Lin et al. (2015) to solve English MWPs (for its potential in solving difficult/complex MWPs and providing more human comprehensible explanations).
32	15	We use the Stanford CoreNLP suite (Manning et al., 2014) as the language analysis module.
36	24	which indicates the stereotype math operation pattern that should be adopted to solve this problem.
54	16	(2) Ai=negative if (VCi, ARi) is either (negative, 4 In our works, the term â€œEntityâ€ also includes the unit of the quantity (e.g., â€œcup of coffeeâ€).
60	13	Let the symbols p, n, s, A, E, R, T, V, SB, SQ and wQ stand for positive, negative, stative, Action, Entity, Relevance, Time, Verb, â€œa body sentenceâ€, â€œthe question sentenceâ€ and â€œa word in question sentenceâ€ respectively.
72	12	Figure 3 shows how to transform the sentence (a) â€œPack 100 candies into 5 boxes.â€ into the corresponding logic form (d).
73	21	First, the dependency tree (b) is transformed into the semantic representation tree (c) adopted by Lin et al., (2015).
85	20	The question in the MWP is also transformed into an FOL-like utility function according to the solution type to ask the logic inference module to find out the answer.
87	13	Since associated operands must be specified before calling those utility functions, a statistical model (see section 2.4) is used to identify the appropriate quantities.
115	25	Here, the probabilistic factor ğ‘ƒğ‘ƒï¿½ğ‘œğ‘œğ‘–ğ‘–ï¿½Î¦(ğ‘ğ‘ğ‘–ğ‘–,ğ•ƒğ•ƒ, ğ‘ ğ‘ )ï¿½ is obtained via an SVM classifier (Chang and Lin, 2011).
127	17	For example, the modifier and place of the quantity in the sentence â€œThere are 30 red flowers in the garden.â€ are â€œredâ€ and â€œgardenâ€ respectively.
143	36	The solution can be obtained by placing correct quantities at appropriate slots.
145	17	random baseline is to solve an MWP by guessing.
179	15	It includes 102 Addition, 147 Subtraction, 101 Multiplication and 46 Division MWPs.
192	12	The last two rows are extracted from (Roy and Roth, 2015).
198	18	Basically, LFT accuracies are from 92% to 95%, and the system accuracies are dominated by STI.
199	12	We analyzed errors resulted from our statistical STI on AI2 and IL datasets, respectively.
200	25	For AI2, major errors come from: (1) failure of ruling out some irrelevant quantities (40%), and (2) making confusion between TVQ-F and Sum these two solution types (20%) for those cases that only involve addition operation (however, both types would return the same answer).
206	31	However, these two systems behave very differently while solving the noisy dataset.
213	16	they have in total?â€, where the underlined sentence is the added noisy sentence.
242	21	is first proposed to associate the extracted math quantity with its physical meaning, which then can be used to identify the desired operands and filter out irrelevant quantities.
244	29	We further compare the performance with a typical DNN approach, the results show the proposed approach is still better.
247	27	(2) Proposing a statistical model to select operands by explicitly checking the meanings of quantities against the meaning of the question sentence.
248	23	(3) Designing a noisy dataset to test if a system solves the problems by understanding.
249	18	(4) Proposing a perplexity-flavor measure to assess the complexity of a dataset.
